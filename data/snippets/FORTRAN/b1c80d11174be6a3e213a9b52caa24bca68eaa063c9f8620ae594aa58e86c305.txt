PROGRAM gradient_descent

! This is a program that implements gradient descent for optimizing a multivariate function.
! The user can specify the function, the learning rate, and the number of iterations.

! Set up the program to read user input from command line
CHARACTER(10) :: func_name ! variable to store user-specified function name
REAL :: learning_rate ! variable to store user-specified learning rate
INTEGER :: max_iters ! variable to store user-specified number of iterations

! Prompt the user for function name, learning rate, and number of iterations
WRITE(*,*) 'Enter the name of the function to be optimized:'
READ(*,*) func_name
WRITE(*,*) 'Enter the learning rate (a value between 0 and 1):'
READ(*,*) learning_rate
WRITE(*,*) 'Enter the maximum number of iterations:'
READ(*,*) max_iters

! Define the function to be optimized
REAL FUNCTION func(x)
    IMPLICIT NONE
    REAL, INTENT(IN) :: x ! input argument
    ! Function definition goes here
    func = x**2 + 3*x + 5
END FUNCTION func

! Define the gradient function of the input function
REAL FUNCTION grad_func(x)
    IMPLICIT NONE
    REAL, INTENT(IN) :: x ! input argument
    ! Gradient function definition goes here
    grad_func = 2*x + 3
END FUNCTION grad_func

! Initialize variables for gradient descent
REAL :: x_curr ! current value of x
REAL :: x_next ! next value of x after gradient descent
INTEGER :: iter ! iteration counter

! Set initial value of x
x_curr = 0.0

! Start the gradient descent iteration
DO iter = 1, max_iters
    ! Calculate the gradient of the function at the current value of x
    REAL :: grad ! variable to store gradient value
    grad = grad_func(x_curr)

    ! Update the value of x using the gradient descent formula
    x_next = x_curr - learning_rate * grad

    ! Check for convergence by comparing the difference between current and next x values
    IF (ABS(x_next - x_curr) < 1e-6) THEN
        EXIT ! exit the loop if the difference is very small
    END IF

    ! Update the value of current x for the next iteration
    x_curr = x_next
END DO

! Print final output of gradient descent
WRITE(*,*) 'The optimized value of x is:', x_curr
WRITE(*,*) 'The minimum value of the function is:', func(x_curr)

END PROGRAM gradient_descent