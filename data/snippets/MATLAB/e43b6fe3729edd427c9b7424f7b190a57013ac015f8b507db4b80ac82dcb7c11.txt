%% Conjugate Gradient Method for solving linear systems of equations
function [x, error] = conjugate_gradient_method(A, b, x_0, max_iter, tol) % Define function with input arguments A, b, initial guess x_0, maximum iterations, and tolerance
% A - coefficient matrix of system
% b - column vector representing right-hand side of system
% x_0 - initial guess for solution vector x
% max_iter - maximum number of iterations to run
% tol - tolerance for convergence criteria 

x = x_0; % Set initial guess to be the starting solution vector
r = b - A*x; % Calculate initial residual using Ax = b

p = r; % Set initial search direction as residual
r_old = r; % Keep track of previous residual for updating beta
error = norm(r); % Calculate initial error vector norm

for i = 1:max_iter % Loop through iterations
    alpha = (r'*r) / (p'*A*p); % Calculate steplength alpha using conjugate gradient formula
    x = x + alpha*p; % Update solution vector
    r = r - alpha*A*p; % Update residual using new alpha value
    
    beta = (r'*r) / (r_old'*r_old); % Calculate beta for updating search direction
    p = r + beta*p; % Update search direction using beta value
    
    error = [error, norm(r)]; % Append new error value to error vector
    
    if norm(r) < tol % Check convergence criteria
        break % Exit out of loop if tolerance has been met
    end
    
    r_old = r; % Update previous residual value
end
% Print final solution vector, residual norm, and error vector
disp(['Solution Vector: ' num2str(x)])
disp(['Residual Norm: ' num2str(norm(r))])
disp(['Error Vector: ' num2str(error)])