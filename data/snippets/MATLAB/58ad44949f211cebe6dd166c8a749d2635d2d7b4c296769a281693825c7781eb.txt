% Initialize variables
num_iterations = 100; % Number of iterations to run
alpha = 0.01; % Learning rate
lambda = 0.1; % Regularization parameter
m = size(X,1); % Number of training examples
weights = zeros(n,1); % Initialize weights to zero

for i = 1:num_iterations % Loop for specified number of iterations
    
    % Forward propagation
    z = X * weights; % Linear combination of inputs and weights
    a = sigmoid(z); % Apply sigmoid function to get predictions
    
    % Calculate cost function
    J = (1/m) * sum(-y .* log(a) - (1-y) .* log(1-a)) + (lambda/(2*m)) * sum(weights(2:end).^2);
    
    % Regularization term
    grad_reg = (lambda/m) * weights;
    grad_reg(1) = 0; % Set first term to 0 to exclude bias term from regularization
    
    % Backpropagation
    d_weights = (1/m) * ((a-y)' * X)' + grad_reg; % Derivative of weights
    
    % Update weights
    weights = weights - alpha * d_weights;
end

% Function to calculate sigmoid
function g = sigmoid(z)
    g = 1 ./ (1 + exp(-z));
end