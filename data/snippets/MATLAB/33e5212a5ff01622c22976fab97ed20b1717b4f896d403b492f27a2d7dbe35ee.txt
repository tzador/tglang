%%% This code snippet implements a gradient descent algorithm to optimize a linear model
%%% with multiple features and a regularized cost function
%%% Inputs:
%%% X - training data matrix, each row represents a training example, first column is the intercept term
%%% y - vector of target outputs for each training example
%%% lambda - regularization parameter
%%% num_iters - number of iterations for gradient descent
%%% alpha - learning rate for gradient descent
%%% Outputs:
%%% theta - vector of optimized parameters for linear model

% initializing theta to all zeros
theta = zeros(size(X,2),1);

% defining the hypothesis function for linear model
h = @(theta) X*theta;

% computing the cost function
J = (1/(2*size(X,1)))*sum((h(theta)-y).^2) + (lambda/(2*size(X,1)))*sum(theta(2:end).^2);

% initializing gradient descent parameters
grad = zeros(size(theta));
temp = zeros(size(theta));

% running gradient descent for specified number of iterations
for i = 1:num_iters
    
    % updating gradient descent parameters
    grad(1) = (1/size(X,1))*sum((h(theta)-y).*X(:,1));
    grad(2:end) = (1/size(X,1))*sum(((h(theta)-y).*X(:,2:end)),1)' + (lambda/size(X,1))*theta(2:end);
    
    % updating theta using gradient descent update rule
    temp(1) = theta(1) - alpha*grad(1);
    temp(2:end) = theta(2:end) - alpha*grad(2:end);
    theta = temp;
    
    % computing new cost function
    J = (1/(2*size(X,1)))*sum((h(theta)-y).^2) + (lambda/(2*size(X,1)))*sum(theta(2:end).^2);
    
end

% returning optimized theta vector as output
theta