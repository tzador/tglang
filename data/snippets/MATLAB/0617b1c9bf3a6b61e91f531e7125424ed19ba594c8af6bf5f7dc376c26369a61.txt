% This code snippet performs linear regression using the least squares method
% Input data is a matrix X containing n samples and m features
% Output variables are the regression coefficients, beta, and the fitted values, y_hat
% We first add a column of ones to X to account for the intercept term
X = [ones(n,1) X]; 

% Calculate the pseudo-inverse of X using the Singular Value Decomposition method
[~, ~, V] = svd(X); 
S = diag(V) ./ sum(V.^2); 
S = diag(S); 
S(isinf(S)) = 0; 
X_pinv = V * S' * V';

% Calculate the regression coefficients using the least squares formula
beta = X_pinv * y;

% Calculate the fitted values
y_hat = X * beta;

% Plot the original data points and the fitted line
plot(X(:,2), y, 'o') 
hold on
plot(X(:,2), y_hat) 
xlabel('Feature') 
ylabel('Target') 
title('Linear Regression with the Least Squares Method') 
legend('Data Points', 'Fitted Line')