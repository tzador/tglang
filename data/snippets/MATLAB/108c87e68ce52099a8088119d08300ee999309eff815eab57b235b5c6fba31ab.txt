% This code snippet is a function that calculates the gradient descent algorithm for linear regression
% Inputs:
% X - matrix of training examples
% y - vector of training labels
% alpha - learning rate
% epochs - number of training iterations
% tol - tolerance for stopping criteria
% Outputs:
% theta - final parameter values
function theta = gradient_descent(X, y, alpha, epochs, tol)

% Initialize parameters
theta = zeros(size(X, 2), 1);

% Loop through number of training iterations
for i = 1:epochs
    
    % Calculate predictions using current parameter values
    h = X * theta;
    
    % Calculate error between predictions and actual labels
    error = h - y;
    
    % Calculate gradient using the derivative of the cost function
    gradient = (X' * error) / length(y);
    
    % Update parameters using gradient descent formula
    theta = theta - (alpha * gradient);
    
    % Calculate cost using current parameter values
    cost = (error' * error) / (2 * length(y));
    
    % Check if cost is below tolerance
    if cost < tol
        break;
    end
end
end