% This code snippet creates a neural network with one hidden layer and trains it on a dataset.
% It uses the backpropagation algorithm for training.

% Load dataset
load('dataset.mat');

% Split dataset into training and testing sets
[train_data, test_data, train_labels, test_labels] = split_dataset(data, labels, 0.8);

% Initialize neural network parameters
input_layer_size = size(train_data, 2); % Number of features in dataset
hidden_layer_size = 64; % Number of hidden units in hidden layer
num_labels = 10; % Number of output classes
theta1 = randn(hidden_layer_size, input_layer_size + 1); % Randomly initialize weights for layer 1
theta2 = randn(num_labels, hidden_layer_size + 1); % Randomly initialize weights for layer 2

% Create function handles for cost function and gradient
cost_function = @(params) nn_cost_function(params, input_layer_size, hidden_layer_size, num_labels, train_data, train_labels, 0.1);
gradient = @(params) nn_gradient(params, input_layer_size, hidden_layer_size, num_labels, train_data, train_labels, 0.1);

% Train neural network using backpropagation algorithm
options = optimset('MaxIter', 100); % Set maximum number of iterations
params = fmincg(cost_function, [theta1(:); theta2(:)], options); % Use fmincg function to minimize cost function
theta1 = reshape(params(1:hidden_layer_size * (input_layer_size + 1)), hidden_layer_size, (input_layer_size + 1)); % Extract new weights for layer 1
theta2 = reshape(params((1 + (hidden_layer_size * (input_layer_size + 1))):end), num_labels, (hidden_layer_size + 1)); % Extract new weights for layer 2

% Make predictions on testing set
predictions = predict(theta1, theta2, test_data);

% Print accuracy of neural network on testing set
fprintf('Accuracy on testing set: %f%%\n', mean(double(predictions == test_labels)) * 100);