function [output] = gradient_descent(x,y,alpha,lambda,iterations)
% This function implements gradient descent to minimize the cost function for linear regression
%
% Input:
% x - matrix of features (m x n)
% y - vector of target values (m x 1)
% alpha - learning rate
% lambda - regularization parameter (optional)
% iterations - number of iterations
%
% Output:
% output - optimized linear regression weights (n x 1)
%
% Initialization
[m, n] = size(x); % number of training examples (m) and features (n)
theta = zeros(n, 1); % initialize regression weights to zeros (n x 1)
cost_history = zeros(iterations, 1); % initialize cost history array
%
% Gradient Descent iterations
for i = 1:iterations % loop through each iteration
    % Calculate hypothesis and cost function for current theta
    h = x * theta; % hypothesis (m x 1)
    cost = (1/(2*m)) * sum((h-y).^2) + (lambda/(2*m)) * sum(theta(2:end,:).^2); % cost function (scalar)
    cost_history(i) = cost; % add current cost to cost history array
    % Update theta using gradient descent formula
    % Note: theta(1) is not regularized
    grad = (1/m) * (x' * (h-y)); % gradient (n x 1)
    theta(1) = theta(1) - alpha*grad(1); % update theta(1)
    theta(2:end) = theta(2:end) - alpha*(grad(2:end) + (lambda/m) * theta(2:end)); % update theta(2:end)
end
output = theta; % set output to optimized theta values
end