%% Generate Linearly Separable Data
% This section generates two classes of linearly separable data with 100
% observations each. Each observation has two features, x1 and x2, which are
% uniformly distributed between -5 and 5. The data is stored in variables
% 'classA' and 'classB', where 'classA' contains the data for class 1 and
% 'classB' contains the data for class 2.

classA = [rand(100,1)*10-5, rand(100,1)*10-5]; % Generate 100 observations for class 1 with features x1 and x2
classB = [rand(100,1)*10-5, rand(100,1)*10-5]; % Generate 100 observations for class 2 with features x1 and x2

%% Plot Data
% This section plots the generated data, with class 1 data plotted in blue
% and class 2 data plotted in red. The plot also includes axis labels and a
% title.

figure; % Open a new figure window
scatter(classA(:,1), classA(:,2), 'b'); % Scatter plot of classA data with x1 values on x-axis and x2 values on y-axis, plotted in blue
hold on; % Keep the current plot and add more elements to it
scatter(classB(:,1), classB(:,2), 'r'); % Scatter plot of classB data with x1 values on x-axis and x2 values on y-axis, plotted in red
xlabel('x1'); % Label for x-axis
ylabel('x2'); % Label for y-axis
title('Linearly Separable Data'); % Title of plot

%% Create Tikhonov Regularization Matrix
% This section creates a Tikhonov regularization matrix with a regularization
% parameter of 0.5. The matrix is added to the identity matrix to form the
% penalty matrix, which will be used in a later calculation.

lambda = 0.5; % Regularization parameter
A = eye(2) + lambda*eye(2); % Create Tikhonov regularization matrix by adding lambda times the identity matrix to the identity matrix

%% Calculate Pseudo-Inverse
% This section calculates the pseudo-inverse of the penalty matrix, using
% the built-in 'pinv' function in MATLAB. The result is stored in a
% variable 'pinvA'.

pinvA = pinv(A); % Calculate the pseudo-inverse of the penalty matrix and store in variable 'pinvA'

%% Calculate Optimal Weights
% This section calculates the optimal weights for linear discriminant
% analysis (LDA). The formula used is: w = (X'*pinvA*X)\(X'*pinvA*y), where
% X is the data matrix and y is the class labels. The result is stored in
% a variable 'w'.

X = [classA; classB]; % Create data matrix by concatenating classA and classB
y = [ones(100,1); -ones(100,1)]; % Create class labels, where 1 represents class 1 and -1 represents class 2
w = (X'*pinvA*X)\(X'*pinvA*y); % Calculate optimal weights using LDA formula and store in variable 'w'