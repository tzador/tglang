%% This code snippet performs k-nearest neighbors classification on a dataset
% Load the dataset
load fisheriris % Iris flower dataset
% Split the dataset into training and testing sets
cv = cvpartition(size(meas,1),'HoldOut',0.2); % 80% of the data will be used for training
idx = cv.test;
% Separate the training and testing data
train_data = meas(~idx,:);
train_labels = species(~idx,:);
test_data = meas(idx,:);
test_labels = species(idx,:);
% Find the optimal k value
k_values = [1:10];
accuracy = zeros(1,10);
for i=1:10
    knn_model = fitcknn(train_data,train_labels,'NumNeighbors',k_values(i),'Distance','euclidean'); % Train the model
    knn_model_predictions = predict(knn_model,test_data); % Test the model
    accuracy(i) = sum(strcmp(knn_model_predictions,test_labels))/length(test_labels); % Calculate classification accuracy
end
[optimal_k,~] = max(accuracy); % Find the optimal k value
fprintf('The optimal k value is: %d \n',optimal_k);
% Train the final model with optimal k value on entire dataset
final_model = fitcknn(meas,species,'NumNeighbors',optimal_k,'Distance','euclidean');
% Make predictions on a new set of data
new_data = [7.5, 3.2, 6.4, 2.0; 6.3, 2.7, 4.9, 1.8];
new_predictions = predict(final_model,new_data);
fprintf('Predictions for the new data are: \n')
disp(new_predictions);