begin
    # Import necessary libraries
    import numpy as np
    import pandas as pd
    import seaborn as sns
    from sklearn.linear_model import LinearRegression

    # Load data
    data = pd.read_csv('data.csv')

    # Preprocessing
    # Identify target variable
    target = data['target']

    # Drop unnecessary columns
    data.drop(['column1', 'column2'], axis=1, inplace=True)

    # Check for missing values
    data.isnull().sum()

    # Impute missing values with mean
    data['column3'].fillna(data['column3'].mean(), inplace=True)

    # Create dummy variables for categorical features
    data = pd.get_dummies(data, columns=['column4', 'column5'], drop_first=True)

    # Split data into train and test sets
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=42)

    # Feature scaling
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Model training
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Model evaluation
    from sklearn.metrics import r2_score
    y_pred = model.predict(X_test)
    print("R-squared score: {}".format(r2_score(y_test, y_pred)))

end