# This is a complex code snippet that uses various Python libraries and modules to perform a specific task.

import pandas as pd # Importing pandas for data analysis
import sklearn # Importing scikit-learn for machine learning algorithms
import matplotlib.pyplot as plt # Importing matplotlib for data visualization

# Loading dataset using pandas
dataset = pd.read_csv("data.csv")

# Data preprocessing steps
# Splitting the dataset into features and target variable
X = dataset.iloc[:, :-1].values # Features (all columns except last)
y = dataset.iloc[:, -1].values # Target variable (last column)

# Handling missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy="mean") # Replacing missing values with mean
X[:, 1:] = imputer.fit_transform(X[:, 1:])

# Encoding categorical data using One Hot Encoding
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[("encoder", OneHotEncoder(), [0])], remainder="passthrough")
X = np.array(ct.fit_transform(X))

# Feature scaling using Standardization
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)

# Splitting into training and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training a Support Vector Machine Classifier on the training set
from sklearn.svm import SVC
classifier = SVC(random_state=42)
classifier.fit(X_train, y_train)

# Making predictions on the test set
y_pred = classifier.predict(X_test)

# Evaluating the model's performance
from sklearn.metrics import confusion_matrix, classification_report
cm = confusion_matrix(y_test, y_pred)
print(classification_report(y_test, y_pred))

# Plotting the decision boundary of the model on the training set
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.01),
                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha=0.75, cmap=ListedColormap(("red", "green")))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c=ListedColormap(("red", "green"))(i), label=j)
plt.title("SVM Classifier (Training set)")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()

# Saving the model to a file
import pickle
with open("svm_classifier.pkl", "wb") as file:
    pickle.dump(classifier, file)

# Loading the model from the saved file
with open("svm_classifier.pkl", "rb") as file:
    svm_classifier = pickle.load(file)
    
# Using the loaded model to make predictions on a new dataset
new_data = [[0, 1, 27, 1, 0, 0, 50000, 6, 1, 1, 0, 24500, 1, 0, 1]] # New data to be predicted
new_data = ct.transform(new_data) # Applying the same transformations as done on the training set
new_data = sc.transform(new_data)
y_pred_new = svm_classifier.predict(new_data) # Predicting the target variable for the new data

# Printing the predicted value
print("The predicted value for the new data is:", y_pred_new)