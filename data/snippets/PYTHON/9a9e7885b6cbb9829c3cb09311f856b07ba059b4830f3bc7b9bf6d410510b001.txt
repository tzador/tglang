# Import necessary libraries
import numpy as np
import pandas as pd

# Set initial values
n = 10
alpha = 0.05
beta = 0.1

# Generate random dataset
x = np.random.randn(n)
y = np.random.randn(n)

# Create a DataFrame
data = pd.DataFrame(np.column_stack((x, y)), columns=['X', 'Y'])

# Define cost function
def cost_function(alpha, beta, x, y):
    cost = np.sum((y - alpha * x - beta)**2)
    return cost

# Define gradient descent function
def gradient_descent(alpha, beta, x, y):
    alpha_grad = 0
    beta_grad = 0
    for i in range(n):
        alpha_grad += -2 * x[i] * (y[i] - alpha * x[i] - beta)
        beta_grad += -2 * (y[i] - alpha * x[i] - beta)
    alpha_new = alpha - alpha_grad * 0.01
    beta_new = beta - beta_grad * 0.01
    return alpha_new, beta_new

# Initialize alpha and beta
alpha_new = alpha
beta_new = beta

# Set convergence threshold
epsilon = 0.0001
# Set max iterations
max_iter = 1000

# Loop for gradient descent
for i in range(0, max_iter):
    alpha_prev = alpha_new
    beta_prev = beta_new

    # Calculate new values for alpha and beta
    alpha_new, beta_new = gradient_descent(alpha_prev, beta_prev, x, y)

    # Check for convergence
    if abs(alpha_new - alpha_prev) < epsilon and abs(beta_new - beta_prev) < epsilon:
        break
        
# Print final values
print("Estimated alpha: ", alpha_new)
print("Estimated beta: ", beta_new)
print("Cost function value: ", cost_function(alpha_new, beta_new, x, y))