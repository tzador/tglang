# Sample code for performing gradient descent optimization in Python
# Import necessary libraries
import numpy as np                 # for handling arrays and matrices
import matplotlib.pyplot as plt    # for visualization
from sklearn.datasets import make_regression    # for generating dummy dataset

# Define function for performing gradient descent
def gradient_descent(X, y, w, alpha, iterations):
    m = len(y)    # number of training examples
    J_history = np.zeros(iterations)    # array to store cost function values over iterations

    # Implement gradient descent over specified number of iterations
    for i in range(iterations):
        # Calculate predicted values using current weights
        y_pred = np.dot(X, w)

        # Calculate cost function value
        J = np.sum((y_pred - y) ** 2) / (2 * m)
        J_history[i] = J

        # Calculate gradient of cost function w.r.t weights
        grad = np.dot(X.T, (y_pred - y)) / m

        # Update weights using gradient descent update rule
        w = w - alpha * grad

    # Return optimized weights and cost function values history
    return w, J_history

# Generate dummy dataset using sklearn's make_regression function
X, y = make_regression(n_samples=100, n_features=1, noise=20)

# Initialize weights to zeros
w = np.zeros(X.shape[1])

# Set learning rate and number of iterations
alpha = 0.01
iterations = 1000

# Perform gradient descent on the dataset
optimized_weights, cost_history = gradient_descent(X, y, w, alpha, iterations)

# Plot cost function values over iterations
plt.plot(range(iterations), cost_history)
plt.xlabel('Iterations')
plt.ylabel('Cost Function')
plt.title('Gradient Descent Optimization')
plt.show()  # display plot