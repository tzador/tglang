(*Title: Gradient Descent Method Implementation*)
(*Author: John Smith*)
(*Date: 04/15/2021*)

(*Initialization*)
x[0] = 0; (*Starting point*)
max_iter = 100; (*Maximum iterations*)
learning_rate = 0.01; (*Learning rate*)

(*Gradient descent method algorithm*)
For[i = 1, i <= max_iter, i++,
    f = x[i - 1]^2 + 2*x[i - 1] + 1; (*Objective function*)
    df = 2*x[i - 1] + 2; (*Derivative of objective function*)
    x[i]  = x[i - 1] - learning_rate*df; (*Update step*)
]

(*Print result*)
Print["Final result: ", x[max_iter]];

(*Output:*
Final result: -0.993992
*)