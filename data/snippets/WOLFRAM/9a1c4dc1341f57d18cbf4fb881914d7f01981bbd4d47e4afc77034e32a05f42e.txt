(* Deep Convolutional Neural Network architecture with Leaky ReLU activation and batch normalization *)
ConvNet[inputSize_, outputSize_, batchSize_] := Module[
 {net, conv1, bn1, relu1, conv2, bn2, relu2, conv3, bn3, relu3, fullyConnected1, bn4, leakyReLU1, fullyConnected2, bn5, leakyReLU2, outputLayer},
  net = NetGraph[
   {
    "ConvolutionLayer1" -> ConvolutionLayer[32, {3, 3}],
    "BatchNormalization1" -> BatchNormalizationLayer[],
    "LeakyReLU1" -> ElementwiseLayer[Ramp[#] + 0.01 Min[#, 0] &],
    "ConvolutionLayer2" -> ConvolutionLayer[64, {3, 3}],
    "BatchNormalization2" -> BatchNormalizationLayer[],
    "LeakyReLU2" -> ElementwiseLayer[Ramp[#] + 0.01 Min[#, 0] &],
    "ConvolutionLayer3" -> ConvolutionLayer[128, {3, 3}],
    "BatchNormalization3" -> BatchNormalizationLayer[],
    "LeakyReLU3" -> ElementwiseLayer[Ramp[#] + 0.01 Min[#, 0] &],
    "FullyConnectedLayer1" -> FullyConnectedLayer[128],
    "BatchNormalization4" -> BatchNormalizationLayer[],
    "LeakyReLU4" -> ElementwiseLayer[Ramp[#] + 0.01 Min[#, 0] &],
    "FullyConnectedLayer2" -> FullyConnectedLayer[outputSize],
    "BatchNormalization5" -> BatchNormalizationLayer[],
    "LeakyReLU5" -> ElementwiseLayer[Ramp[#] + 0.01 Min[#, 0] &],
    "OutputLayer" -> LinearLayer[outputSize]
   },
   {
    NetPort["Input"] -> "ConvolutionLayer1" -> "BatchNormalization1" -> "LeakyReLU1" -> "ConvolutionLayer2" -> "BatchNormalization2" -> "LeakyReLU2" -> "ConvolutionLayer3" -> "BatchNormalization3" -> "LeakyReLU3" -> "FullyConnectedLayer1" -> "BatchNormalization4" -> "LeakyReLU4" -> "FullyConnectedLayer2" -> "BatchNormalization5" -> "LeakyReLU5" -> "OutputLayer"
   },
   "Input" -> NetEncoder[{"Image", {inputSize, inputSize}, ColorSpace -> "Grayscale"}],
   "Output" -> NetDecoder["Class"]
  ];
  NetTrain[net, batchDataset, TargetDevice -> "GPU", BatchSize -> batchSize, 
   LearningRateMultipliers -> {"ConvolutionLayer1" -> 1, "ConvolutionLayer2" -> 1, "ConvolutionLayer3" -> 1, "FullyConnectedLayer1" -> 1, "FullyConnectedLayer2" -> 1}]
 ]