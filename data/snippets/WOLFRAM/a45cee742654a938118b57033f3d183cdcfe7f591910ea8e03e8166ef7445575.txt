(* Initializing variables *)
ClearAll["Global`*"]
n = 10;  (* number of iterations *)
alpha = 0.5;  (* learning rate *)
Lambda = 1;  (* regularization parameter *)

(* Generating random data *)
x = RandomReal[1, {n, 3}];  (* input matrix with 3 features *)
y = RandomInteger[{0, 1}, n];  (* output vector of binary labels *)

(* Defining the sigmoid function *)
sigmoid[z_] := 1/(1 + Exp[-z])

(* Defining the cost function *)
costFunction[w_] := (
  h = sigmoid[x.w];
  J = -1/n * Sum[y[[i]]*Log[h[[i]]] + (1 - y[[i]])*Log[1 - h[[i]]], {i, n}] + (Lambda/2n) * Sum[w[[j]]^2, {j, 2}];
  Return[J]
)

(* Performing gradient descent *)
w = RandomReal[1, {3}];  (* initializing weight vector *)
Do[
  h = sigmoid[x.w];
  gradient = (1/n) * Transpose[x].(h - y) + (Lambda/n) * w;
  w = w - alpha * gradient;
, {i, n}]

(* Printing the final weight vector and cost *)
Print["Final weight vector: ", w]
Print["Final cost: ", costFunction[w]]