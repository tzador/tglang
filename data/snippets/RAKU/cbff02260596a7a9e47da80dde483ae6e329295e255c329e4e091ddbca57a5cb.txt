use WWW::Mechanize; # Import the WWW::Mechanize module
use HTML::Entities; # Import the HTML::Entities module

my $mech = WWW::Mechanize.new; # Create a new instance of the WWW::Mechanize class
my $url = "https://en.wikipedia.org/wiki/Raku_(programming_language)"; # Define the URL to be scraped

$mech.get($url); # Use the 'get' method to retrieve the content of the URL

my @links = $mech.links; # Use the 'links' method to retrieve all the links on the page
my @title; # Define an empty array to store the titles of the retrieved links
my @content; # Define an empty array to store the content of the retrieved links

# Loop through each link and extract the title and content
for @links -> $link {
    push @title, $link.text; # Add the title of the link to the 'title' array
    push @content, HTML::Entities.decode($mech.follow_link($link).text); # Follow the link and add the decoded content to the 'content' array
    $mech.back; # Return to the previous page
}

# Print the titles and content of the retrieved links
say "Titles:";
for @title -> $t {
    say $t;
}
say "Content:";
for @content -> $c {
    say $c;
}