# This program uses the Ruby gem 'Nokogiri' to scrape data from a website and write it to a CSV file
require 'nokogiri' # Import the gem
require 'csv'

# Define a method to scrape data from a given URL
def scrape_data(url)
  page = Nokogiri::HTML(open(url)) # Open the webpage and parse it with Nokogiri
  data = [] # Define an empty array to store the scraped data

  # Loop through each element in the webpage that has the specified class
  page.css('.data-row').each do |row|
    # Create a hash to store the data for each row
    row_data = {
      name: row.css('.name').text, # Use CSS selectors to extract data from specific elements
      age: row.css('.age').text,
      occupation: row.css('.occupation').text
    }
    data << row_data # Add the row data hash to the data array
  end

  return data # Return the data array
end

# Call the scrape_data method and pass in the URL
scraped_data = scrape_data('https://www.example.com')

# Write the data to a CSV file using the CSV gem
CSV.open('data.csv', 'w') do |csv|
  # Write the headers for each column in the CSV file
  csv << ['Name', 'Age', 'Occupation']

  # Loop through each scraped row and write the data to the CSV file
  scraped_data.each do |row|
    csv << [row[:name], row[:age], row[:occupation]] # Use bracket notation to access the values in the row_data hash
  end
end