--[[ Simple Linear Regression Model in LUA ]]
function trainModel(x, y, learningRate)
    --[[ x: A table of input data (NxM) where N is the number of samples and M is the number of features. 
           Each sample should have a corresponding output value in the table y.  ]]
    --[[ y: A table of output data (Nx1) ]]
    --[[ learningRate: A float value that determines the size of the updates made to the model's parameters during training. ]]
    
    -- Initialize model parameters (weights and bias)
    local w = {} 
    local b = 0
    
    -- Define model function
    local function model(x)
        return w[1] * x[1] + w[2] * x[2] + b
    end
    
    -- Define loss function (Mean Squared Error)
    local function loss(y_pred, y)
        return (y_pred - y)^2
    end
    
    -- Define gradient function (partial derivatives of w and b with respect to loss function)
    local function gradient(x, y_pred, y)
        local dw1 = 2 * x[1] * (y_pred - y)
        local dw2 = 2 * x[2] * (y_pred - y)
        local db = 2 * (y_pred - y)
        return dw1, dw2, db
    end
    
    -- Train model using gradient descent
    for i = 1, #x do
        -- Make prediction
        local y_pred = model(x[i])
        
        -- Calculate loss
        local cost = loss(y_pred, y[i])
        
        -- Calculate gradients
        local dw1, dw2, db = gradient(x[i], y_pred, y[i])
        
        -- Update parameters 
        w[1] = w[1] - learningRate * dw1
        w[2] = w[2] - learningRate * dw2
        b = b - learningRate * db
    end
    
    -- Return trained model
    return model
end

-- Example usage
local x = {{1, 2}, {2, 3}, {3, 4}, {4, 5}} -- Input data
local y = {3, 5, 7, 9} -- Output data
local lr = 0.01 -- Learning rate
local model = trainModel(x, y, lr) -- Train model
print(model({5, 6})) -- Make prediction using trained model