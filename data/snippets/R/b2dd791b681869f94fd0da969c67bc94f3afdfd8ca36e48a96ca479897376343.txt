# Function to perform gradient descent optimization
# Inputs:
# - alpha: learning rate
# - x: input data
# - y: output data
# - numIterations: number of iterations
#
# Outputs:
# - theta: optimized parameters
#
# Initialize theta with random values
theta <- runif(n = length(x[,1]), min = 0, max = 1)
gradient_descent <- function(alpha, x, y, numIterations) {
  for (i in 1:numIterations) {
    # Calculate predictions
    predictions <- x %*% t(theta)
    
    # Calculate error
    error <- predictions - y
    
    # Calculate gradient
    gradient <- t(x) %*% error
    
    # Update theta
    theta <- theta - (alpha * gradient)
  }
  
  return(theta)
}

# Call gradient descent function
optimized_theta <- gradient_descent(alpha = 0.01, x = input_data, y = output_data, numIterations = 100)