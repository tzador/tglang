# This code snippet generates a neural network model to classify handwritten digits using the MNIST dataset
library(keras)

# Load the MNIST dataset
mnist <- dataset_mnist()

# Preprocess the data
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y

# Scale the data
x_train <- x_train / 255
x_test <- x_test / 255

# Define the model architecture
model <- keras_model_sequential()
model %>% 
  layer_dense(units = 512, activation = 'relu', input_shape = c(28*28)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256, activation = 'relu') %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 10, activation = 'softmax')

# Compile the model
model %>% compile(
  loss = 'sparse_categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)

# Train the model
history <- model %>% fit(
  x_train, y_train,
  epochs = 5,
  batch_size = 128,
  validation_split = 0.2
)

# Evaluate the model on the test data
test_loss <- model %>% evaluate(x_test, y_test)
cat('Test loss:', test_loss[[1]])
cat('Test accuracy:', test_loss[[2]])

# Predict on new data
predictions <- model %>% predict(x_test)

# Plot the training and validation accuracy over epochs
plot(history$acc, type='b', col='blue', xlab='Epochs', ylab='Accuracy', main='Training and Validation Accuracy', ylim=c(0.9,1))
lines(history$val_acc, type='b', col='red')
legend('bottomright', c('Training', 'Validation'), fill=c('blue', 'red'))