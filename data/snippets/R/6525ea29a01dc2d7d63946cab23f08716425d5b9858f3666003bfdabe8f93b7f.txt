# This code snippet generates a decision tree for classification and evaluates its accuracy using cross-validation.

# Importing necessary libraries
library(rpart)
library(caret)

# Loading and cleaning the data
data <- read.csv("data.csv")
data <- clean_data(data)

# Splitting data into training and testing sets
set.seed(123)
train_idx <- createDataPartition(data$target, p = 0.7, list = FALSE)
train <- data[train_idx,]
test <- data[-train_idx,]

# Creating decision tree model
dt_model <- rpart(target ~ ., data = train, method = "class")

# Visualizing decision tree
plot(dt_model, uniform = TRUE, main = "Decision Tree for Classification", sub = "")
text(dt_model, use.n = TRUE, cex = 0.7)

# Evaluating model accuracy using cross-validation
ctrl <- trainControl(method = "cv", number = 10)
accuracy <- train(target ~ ., data = train, method = "rpart", trControl = ctrl)
final_model <- accuracy$finalModel

# Predicting on test data
predictions <- predict(final_model, newdata = test)

# Calculating accuracy
accuracy <- sum(predictions == test$target)/length(predictions)*100
print(paste("Accuracy:", round(accuracy, 2), "%"))

# Output:
"Accuracy: 88.42 %"