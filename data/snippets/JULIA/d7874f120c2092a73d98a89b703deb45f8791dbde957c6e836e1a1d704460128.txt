function lasso(X, y; lambda=1.0)
    # Define the size of the input matrix X
    n, p = size(X)

    # Calculate the Gram matrix (X'X)
    gram_matrix = transpose(X)*X

    # Set the initial value for beta vector
    beta = zeros(p)

    # Define the maximum number of iterations
    max_iter = 100

    # Define the tolerance for the convergence criteria
    tol = 0.0001

    # Set the initial cost and iteration values
    cost = Inf
    iter = 0

    # Loop until convergence or maximum iterations reached
    while cost > tol && iter < max_iter
        # Calculate the current cost
        curr_cost = sum((X*beta - y).^2)/n + lambda*norm(beta, 1)

        # Update the beta vector using soft-thresholding
        for i in 1:p
            beta[i] = sign(beta[i])*max(abs(beta[i]) - lambda/n, 0)
        end

        # Calculate the new cost
        cost = sum((X*beta - y).^2)/n + lambda*norm(beta, 1)

        # Update the iteration count
        iter += 1
    end

    # Return the final beta vector
    return beta
end