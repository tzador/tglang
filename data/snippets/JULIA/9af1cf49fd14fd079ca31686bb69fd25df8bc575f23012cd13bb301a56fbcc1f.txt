function gradient_descent(x, y, alpha, num_iters)
    # This function implements gradient descent for linear regression in Julia
    # Inputs:
    # x - an m x n matrix of features
    # y - an m x 1 vector of labels
    # alpha - learning rate
    # num_iters - number of iterations for gradient descent
    # Outputs:
    # theta - an n x 1 vector of learned linear regression parameters

    # Initialize theta to be a n x 1 vector of zeros
    theta = zeros(size(x, 2))

    for iter in 1:num_iters
        # Calculate hypothesis using current theta values
        h = x * theta

        # Calculate the cost function
        J = (1/(2*m)) * sum((h - y).^2)

        # Update theta values
        theta = theta - (alpha/m) * (x' * (h - y))
    end

    return theta
end