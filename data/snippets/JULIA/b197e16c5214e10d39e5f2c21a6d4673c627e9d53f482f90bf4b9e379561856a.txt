### Julia code for gradient descent algorithm ###
# Define the objective function
f(x) = 3x^2 + 3x + 1

# Define the gradient function
∇f(x) = 6x + 3

# Define the learning rate
α = 0.1

# Define the initial guess
x0 = 5.0

# Set up the stopping criterion
tol = 1e-6

# Set up a counter for iterations
iter = 0

# Set up a maximum number of iterations
maxiter = 100

# Define a variable to store the previous value of x
prev_x = 0.0

# Define a variable to store the current value of x
x = x0

# Perform gradient descent algorithm
while norm(x - prev_x) > tol && iter < maxiter
    prev_x = x
    
    # Update x using gradient descent formula
    x = x - α*∇f(x)
    
    # Increment iteration counter
    iter += 1
    
    # Print current iteration and x value
    println("Iteration $iter: x = $x")
    
    # Check for convergence
    if iter == maxiter
        println("Maximum number of iterations reached")
    end
end

# Print final result
println("Optimal value of x = $x")