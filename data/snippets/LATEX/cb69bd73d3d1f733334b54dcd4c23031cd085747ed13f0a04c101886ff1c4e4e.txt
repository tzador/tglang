\begin{algorithm}

\SetAlgoLined % specifies vertical lines for the algorithm
\KwIn{dataset $D = \{x_1, x_2, ..., x_n\}$} % specifies input
\KwResult{fitted model $M$} % specifies output

% initialize variables
$\theta_0 \leftarrow 0$ \; % initialize theta_0, sets left arrow
$\theta_1 \leftarrow 0$ \; % initialize theta_1, sets left arrow
$\alpha \leftarrow 0.01$ \; % initialize learning rate, sets left arrow
$iterations \leftarrow 10000$ \; % specify number of iterations, sets left arrow
$m \leftarrow size(D)$ \; % get size of dataset, sets left arrow 

\For{$i$ in $\{1, 2, ..., iterations\}$}{ % specifies for loop
	
	% initialize variables for gradient descent
	$h \leftarrow \theta_0 + \theta_1 x$ \; % calculates hypothesis, sets left arrow
	$error \leftarrow h - y$ \; % calculates error, sets left arrow
	$grad\_0 \leftarrow \frac{1}{m} \sum_{j=1}^{m} error$ \; % calculates gradient for theta_0, sets left arrow
	$grad\_1 \leftarrow \frac{1}{m} \sum_{j=1}^{m} error*x$ \; % calculates gradient for theta_1, sets left arrow
	% update theta_0 and theta_1
	$\theta_0 \leftarrow \theta_0 - \alpha * grad\_0$ \; % updates theta_0, sets left arrow
	$\theta_1 \leftarrow \theta_1 - \alpha * grad\_1$ \; % updates theta_1, sets left arrow
}
fitted model $M = \{\theta_0, \theta_1\}$ \; % save final parameters as the fitted model

\caption{Gradient Descent} % specifies the caption for the algorithm
\end{algorithm}